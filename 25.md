### Роль Data Mining в BI, СППР. Информационные потоки от источников до решений

### **Часть 1. Data Mining в контексте BI и СППР**

#### **1.1. Определение и эволюция**

**Data Mining (интеллектуальный анализ данных)** — это процесс обнаружения скрытых, ранее неизвестных, нетривиальных, практически полезных и интерпретируемых закономерностей в больших объемах данных.

**Эволюция аналитики:**
```
1980-е: Оперативная отчетность (что произошло?)
    ↓
1990-е: Бизнес-интеллект (почему произошло?)
    ↓
2000-е: Прогнозная аналитика (что произойдет?)
    ↓
2010-е: Предписывающая аналитика (что делать?)
    ↓
2020-е: Автономные системы (самооптимизация)
```

#### **1.2. Место Data Mining в BI и СППР**

**Иерархия аналитических систем:**
```
┌─────────────────────────────────────────────────┐
│      СППР (Система Поддержки Принятия Решений)   │
│  • Стратегическое управление                    │
│  • Что-если анализ                              │
│  • Оптимизация решений                          │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│        BI (Business Intelligence)                │
│  • Отчетность, дашборды                         │
│  • OLAP-анализ                                  │
│  • Ad-hoc запросы                              │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│           Data Mining                            │
│  • Классификация, кластеризация                 │
│  • Ассоциативные правила                        │
│  • Прогнозирование                              │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│       Хранилище данных (DWH)                    │
│  • Интеграция, очистка                          │
│  • Исторические данные                          │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│           Источники данных                       │
│  • OLTP-системы                                 │
│  • Внешние данные                               │
└─────────────────────────────────────────────────┘
```

#### **1.3. Виды аналитики и роль Data Mining**

| Тип аналитики | Вопрос | Методы Data Mining | Пример |
| :--- | :--- | :--- | :--- |
| **Дескриптивная** | Что произошло? | Кластеризация, ассоциативные правила | Сегментация клиентов, анализ корзин |
| **Диагностическая** | Почему произошло? | Деревья решений, анализ взаимосвязей | Причины оттока клиентов |
| **Прогнозная** | Что произойдет? | Регрессия, нейронные сети, временные ряды | Прогноз спроса, вероятность дефолта |
| **Предписывающая** | Что делать? | Оптимизация, симуляции, рекомендательные системы | Оптимальные цены, персональные предложения |

---

### **Часть 2. Основные алгоритмы и методы Data Mining**

#### **2.1. Классификация алгоритмов**

**По типу обучения:**
- **С учителем (Supervised):** Классификация, регрессия
- **Без учителя (Unsupervised):** Кластеризация, ассоциация
- **С частичным привлечением учителя (Semi-supervised):** Гибридные подходы

#### **2.2. Ключевые алгоритмы**

**1. Классификация:**
```sql
-- Деревья решений (CART, C4.5)
CREATE MODEL CustomerChurnModel
WITH (
    ALGORITHM = DECISION_TREE,
    MAX_DEPTH = 10,
    MIN_SPLIT_SIZE = 100
)
AS
SELECT 
    CustomerID,
    Age,
    Tenure,
    MonthlyCharges,
    ContractType,
    Churn  -- Целевая переменная
FROM Customers;

-- Логистическая регрессия
CREATE MODEL PurchaseProbability
WITH (ALGORITHM = LOGISTIC_REGRESSION)
AS
SELECT 
    CustomerID,
    PreviousPurchases,
    TimeSinceLastVisit,
    MarketingExposure,
    MadePurchase  -- 0/1
FROM CustomerInteractions;
```

**2. Кластеризация:**
```sql
-- K-means кластеризация
EXEC sp_execute_external_script
@language = N'R',
@script = N'
    clusters <- kmeans(InputDataSet, centers = 5)
    OutputDataSet <- cbind(InputDataSet, Cluster = clusters$cluster)
',
@input_data_1 = N'
    SELECT 
        AnnualIncome,
        SpendingScore,
        Age
    FROM Customers
';

-- DBSCAN для обнаружения выбросов
CREATE MODEL FraudDetection
WITH (ALGORITHM = DBSCAN, EPS = 0.5, MIN_PTS = 10)
AS
SELECT 
    TransactionID,
    Amount,
    TimeOfDay,
    LocationVariance
FROM Transactions;
```

**3. Ассоциативные правила (Market Basket Analysis):**
```sql
-- Алгоритм Apriori
WITH AssociationRules AS (
    SELECT 
        Antecedent,
        Consequent,
        Support,
        Confidence,
        Lift
    FROM dbo.ExtractAssociationRules(
        (SELECT TransactionID, ProductID FROM TransactionDetails),
        @min_support = 0.01,
        @min_confidence = 0.3
    )
)
SELECT *
FROM AssociationRules
WHERE Lift > 2.0  -- Значимые правила
ORDER BY Lift DESC;

-- Пример результата: {Молоко, Хлеб} → {Яйца}, Support=0.05, Confidence=0.7, Lift=3.2
```

**4. Временные ряды и прогнозирование:**
```sql
-- ARIMA для прогноза продаж
CREATE MODEL SalesForecast
WITH (
    ALGORITHM = ARIMA,
    SEASONALITY = 12,  -- месячная сезонность
    FORECAST_HORIZON = 6
)
AS
SELECT 
    MonthDate,
    SalesAmount
FROM MonthlySales
ORDER BY MonthDate;

-- Прогноз с доверительными интервалами
EXEC PredictSalesForecast
    @model_name = 'SalesForecast',
    @future_periods = 12,
    @include_confidence = 1;
```

**5. Рекомендательные системы:**
```sql
-- Collaborative Filtering
CREATE MODEL ProductRecommendations
WITH (ALGORITHM = MATRIX_FACTORIZATION)
AS
SELECT 
    UserID,
    ProductID,
    Rating
FROM UserRatings;

-- Получение рекомендаций
SELECT 
    UserID,
    RecommendedProductID,
    PredictedRating,
    Confidence
FROM PredictRecommendations(
    @model = 'ProductRecommendations',
    @user_id = 12345,
    @top_n = 10
);
```

#### **2.3. Метрики оценки моделей**

```sql
-- Матрица ошибок для классификации
WITH ConfusionMatrix AS (
    SELECT 
        Actual,
        Predicted,
        COUNT(*) AS Count
    FROM ModelPredictions
    GROUP BY Actual, Predicted
)
SELECT 
    Accuracy = (TP + TN) / (TP + TN + FP + FN),
    Precision = TP / (TP + FP),
    Recall = TP / (TP + FN),
    F1_Score = 2 * Precision * Recall / (Precision + Recall)
FROM (
    SELECT 
        SUM(CASE WHEN Actual = 1 AND Predicted = 1 THEN Count ELSE 0 END) AS TP,
        SUM(CASE WHEN Actual = 0 AND Predicted = 0 THEN Count ELSE 0 END) AS TN,
        SUM(CASE WHEN Actual = 0 AND Predicted = 1 THEN Count ELSE 0 END) AS FP,
        SUM(CASE WHEN Actual = 1 AND Predicted = 0 THEN Count ELSE 0 END) AS FN
    FROM ConfusionMatrix
) AS metrics;

-- AUC-ROC для бинарной классификации
EXEC CalculateAUC 
    @actual_values = 'ActualChurn',
    @predicted_scores = 'ChurnProbability',
    @data_source = 'ModelEvaluation';
```

---

### **Часть 3. Информационные потоки: CRISP-DM методология**

#### **3.1. CRISP-DM (Cross-Industry Standard Process for Data Mining)**

**Этап 1. Бизнес-понимание (Business Understanding):**
```sql
-- Определение бизнес-целей
/* 
Цель: Снизить отток клиентов на 15% в течение квартала
Критерии успеха:
- Точность модели > 85%
- Recall для класса "уйдет" > 90%
- Внедрение в течение 4 недель
*/
```

**Этап 2. Понимание данных (Data Understanding):**
```sql
-- Исследовательский анализ данных
EXEC sp_describe_first_result_set N'
    SELECT 
        CustomerID,
        Age,
        Income,
        TenureMonths,
        MonthlyCharges,
        TotalCharges,
        ChurnFlag
    FROM TelecomCustomers
';

-- Проверка качества данных
WITH DataQuality AS (
    SELECT 
        ColumnName,
        DataType,
        TotalRows,
        NullCount,
        NullPercentage = CAST(NullCount AS FLOAT) / TotalRows * 100,
        DistinctCount,
        MinValue,
        MaxValue,
        AvgValue
    FROM AnalyzeDataQuality('TelecomCustomers')
)
SELECT *
FROM DataQuality
WHERE NullPercentage > 5 OR DistinctCount = 1;
```

**Этап 3. Подготовка данных (Data Preparation):**
```sql
-- Создание аналитического набора данных
CREATE VIEW vw_CustomerAnalytics
AS
WITH CustomerFeatures AS (
    SELECT 
        c.CustomerID,
        -- Демографические признаки
        c.Age,
        c.Gender,
        c.MaritalStatus,
        c.IncomeSegment,
        
        -- Поведенческие признаки
        DATEDIFF(MONTH, c.JoinDate, GETDATE()) AS TenureMonths,
        c.MonthlyCharges,
        c.TotalCharges / NULLIF(DATEDIFF(MONTH, c.JoinDate, GETDATE()), 0) AS AvgMonthlyCharge,
        
        -- Признаки из транзакций
        t.CallCount,
        t.AvgCallDuration,
        t.DataUsageGB,
        
        -- Признаки из сервисной истории
        s.ComplaintCount,
        s.LastComplaintDaysAgo,
        
        -- Целевая переменная
        CASE WHEN c.ChurnDate IS NOT NULL THEN 1 ELSE 0 END AS ChurnLabel
    FROM Customers c
    LEFT JOIN (
        SELECT CustomerID, COUNT(*) AS CallCount, AVG(Duration) AS AvgCallDuration
        FROM Calls GROUP BY CustomerID
    ) t ON c.CustomerID = t.CustomerID
    LEFT JOIN (
        SELECT CustomerID, COUNT(*) AS ComplaintCount, 
               DATEDIFF(DAY, MAX(ComplaintDate), GETDATE()) AS LastComplaintDaysAgo
        FROM Complaints GROUP BY CustomerID
    ) s ON c.CustomerID = s.CustomerID
)
SELECT * FROM CustomerFeatures;

-- Обработка пропусков и выбросов
CREATE PROCEDURE usp_PrepareModelData
AS
BEGIN
    -- Заполнение пропусков
    UPDATE vw_CustomerAnalytics
    SET IncomeSegment = 'Unknown'
    WHERE IncomeSegment IS NULL;
    
    -- Обработка выбросов (winsorization)
    WITH Stats AS (
        SELECT 
            PERCENTILE_CONT(0.05) WITHIN GROUP (ORDER BY MonthlyCharges) OVER() AS P05,
            PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY MonthlyCharges) OVER() AS P95
        FROM vw_CustomerAnalytics
    )
    UPDATE ca
    SET MonthlyCharges = 
        CASE 
            WHEN MonthlyCharges < s.P05 THEN s.P05
            WHEN MonthlyCharges > s.P95 THEN s.P95
            ELSE MonthlyCharges
        END
    FROM vw_CustomerAnalytics ca
    CROSS JOIN Stats s;
    
    -- Создание фич
    ALTER TABLE ModelData ADD
        TenureSegment AS 
            CASE 
                WHEN TenureMonths < 6 THEN 'New'
                WHEN TenureMonths < 24 THEN 'Medium'
                ELSE 'LongTerm'
            END,
        ValueSegment AS
            CASE
                WHEN AvgMonthlyCharge > 100 THEN 'High'
                WHEN AvgMonthlyCharge > 50 THEN 'Medium'
                ELSE 'Low'
            END;
END;
```

**Этап 4. Моделирование (Modeling):**
```sql
-- Разделение на train/test
CREATE TABLE #TrainData (CustomerID INT PRIMARY KEY, IsTrain BIT);
CREATE TABLE #TestData (CustomerID INT PRIMARY KEY, IsTrain BIT);

INSERT INTO #TrainData
SELECT CustomerID, 1
FROM vw_CustomerAnalytics
WHERE CustomerID % 10 < 7;  -- 70% на обучение

INSERT INTO #TestData  
SELECT CustomerID, 0
FROM vw_CustomerAnalytics
WHERE CustomerID % 10 >= 7; -- 30% на тест

-- Обучение нескольких моделей
DECLARE @models TABLE (
    ModelName NVARCHAR(100),
    Algorithm NVARCHAR(100),
    Parameters NVARCHAR(MAX),
    AUC FLOAT,
    Accuracy FLOAT
);

-- Модель 1: Логистическая регрессия
INSERT INTO @models
EXEC TrainLogisticRegression 
    @train_data = '#TrainData',
    @target = 'ChurnLabel',
    @features = 'Age,TenureMonths,MonthlyCharges,ComplaintCount';

-- Модель 2: Случайный лес
INSERT INTO @models  
EXEC TrainRandomForest
    @train_data = '#TrainData',
    @target = 'ChurnLabel',
    @n_estimators = 100,
    @max_depth = 10;

-- Модель 3: Градиентный бустинг
INSERT INTO @models
EXEC TrainGradientBoosting
    @train_data = '#TrainData',
    @target = 'ChurnLabel',
    @learning_rate = 0.1,
    @n_estimators = 200;

-- Выбор лучшей модели
SELECT TOP 1 @best_model = ModelName
FROM @models
ORDER BY AUC DESC;
```

**Этап 5. Оценка (Evaluation):**
```sql
-- Оценка на тестовых данных
WITH Predictions AS (
    SELECT 
        t.CustomerID,
        t.ActualChurn,
        p.PredictedChurn,
        p.ChurnProbability,
        CASE 
            WHEN t.ActualChurn = 1 AND p.PredictedChurn = 1 THEN 'TP'
            WHEN t.ActualChurn = 0 AND p.PredictedChurn = 0 THEN 'TN'
            WHEN t.ActualChurn = 0 AND p.PredictedChurn = 1 THEN 'FP'
            WHEN t.ActualChurn = 1 AND p.PredictedChurn = 0 THEN 'FN'
        END AS ResultType
    FROM TestData t
    JOIN ModelPredictions p ON t.CustomerID = p.CustomerID
)
SELECT 
    ResultType,
    COUNT(*) AS Count,
    AVG(ChurnProbability) AS AvgProbability
FROM Predictions
GROUP BY ResultType;

-- Business validation
DECLARE @campaign_cost DECIMAL(18,2) = 50000;
DECLARE @retention_value DECIMAL(18,2) = 2000; -- Ценность удержания клиента

WITH CampaignROI AS (
    SELECT 
        COUNT(*) AS TargetedCustomers,
        SUM(CASE WHEN ActualChurn = 1 THEN 1 ELSE 0 END) AS PreventedChurns,
        SUM(CASE WHEN ActualChurn = 1 THEN @retention_value ELSE 0 END) - @campaign_cost AS NetValue
    FROM CampaignTargets ct
    JOIN ActualOutcomes ao ON ct.CustomerID = ao.CustomerID
    WHERE ct.InCampaign = 1
)
SELECT 
    TargetedCustomers,
    PreventedChurns,
    NetValue,
    ROI = NetValue / @campaign_cost * 100
FROM CampaignROI;
```

**Этап 6. Внедрение (Deployment):**
```sql
-- Создание production pipeline
CREATE PROCEDURE usp_ScoreNewCustomers
    @batch_date DATE
AS
BEGIN
    -- 1. Извлечение новых данных
    INSERT INTO ScoringQueue (CustomerID, ScoreDate)
    SELECT CustomerID, @batch_date
    FROM NewCustomers
    WHERE CreatedDate >= DATEADD(DAY, -1, @batch_date);
    
    -- 2. Применение модели
    UPDATE sq
    SET 
        ChurnProbability = p.ChurnProbability,
        ChurnRisk = CASE 
            WHEN p.ChurnProbability > 0.7 THEN 'High'
            WHEN p.ChurnProbability > 0.3 THEN 'Medium'
            ELSE 'Low'
        END,
        ScoredDate = GETDATE()
    FROM ScoringQueue sq
    CROSS APPLY PredictChurn(sq.CustomerID) p
    WHERE sq.ScoreDate = @batch_date
        AND sq.ScoredDate IS NULL;
    
    -- 3. Генерация рекомендаций
    INSERT INTO CustomerActions (CustomerID, ActionType, Priority, GeneratedDate)
    SELECT 
        CustomerID,
        CASE 
            WHEN ChurnRisk = 'High' THEN 'PersonalCall'
            WHEN ChurnRisk = 'Medium' THEN 'SpecialOffer'
            ELSE 'Newsletter'
        END,
        CASE ChurnRisk 
            WHEN 'High' THEN 1 
            WHEN 'Medium' THEN 2 
            ELSE 3 
        END,
        GETDATE()
    FROM ScoringQueue
    WHERE ScoreDate = @batch_date
        AND ChurnRisk IN ('High', 'Medium');
END;

-- Создание дашборда для мониторинга
CREATE VIEW vw_ChurnMonitoring
AS
SELECT 
    ScoreDate,
    COUNT(*) AS CustomersScored,
    AVG(ChurnProbability) AS AvgRiskScore,
    SUM(CASE WHEN ChurnRisk = 'High' THEN 1 ELSE 0 END) AS HighRiskCount,
    SUM(CASE WHEN ChurnRisk = 'Medium' THEN 1 ELSE 0 END) AS MediumRiskCount
FROM ScoringQueue
GROUP BY ScoreDate;
```

---

### **Часть 4. Интеграция Data Mining с OLAP и отчетностью**

#### **4.1. Гибридная архитектура: OLAP + Data Mining**

```
┌─────────────────────────────────────────────────┐
│             BI Дашборды и Отчеты                │
│  • Power BI, Tableau                           │
│  • Интеграция моделей в визуализации           │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│         OLAP Кубы + Mining Модели               │
│  • Меры из Data Mining (скоринг, кластеры)      │
│  • Многомерный анализ результатов моделей       │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│        Операционные системы (OLAP + DM)         │
│  • Рекомендации в реальном времени              │
│  • Автоматические решения                       │
└───────────────┬─────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────┐
│        Хранилище данных + Mining Results        │
│  • Исторические данные + предсказания           │
│  • Обогащенные данные (с фичами)                │
└─────────────────────────────────────────────────┘
```

#### **4.2. Интеграционные паттерны**

**Паттерн 1: Mining-меры в OLAP кубах**
```mdx
-- MDX с интегрированными prediction меры
WITH 
MEMBER [Measures].[Churn Probability] AS
    PredictProbability([Customer].CurrentMember, 'ChurnModel')

MEMBER [Measures].[Recommended Product] AS
    PredictTopRecommendation([Customer].CurrentMember, 'RecommendationModel')

SELECT 
    {[Measures].[Sales Amount], 
     [Measures].[Churn Probability],
     [Measures].[Recommended Product]} ON COLUMNS,
    [Customer].[Region].Members ON ROWS
FROM [SalesCube];
```

**Паттерн 2: Обогащение данных через DM**
```sql
-- Добавление кластеров к данным для OLAP анализа
ALTER TABLE Customers ADD
    RFM_Cluster INT,           -- Кластер по Recency-Frequency-Monetary
    ChurnScore DECIMAL(5,4),   -- Скор от модели
    NextBestAction NVARCHAR(50); -- Рекомендация

-- Процедура обновления
CREATE PROCEDURE usp_EnrichCustomerData
AS
BEGIN
    -- Выполнение кластеризации
    EXEC ClusterCustomers 
        @output_column = 'RFM_Cluster';
    
    -- Скоринг оттока
    EXEC ScoreChurnRisk 
        @output_column = 'ChurnScore';
    
    -- Генерация рекомендаций
    EXEC GenerateRecommendations 
        @output_column = 'NextBestAction';
END;
```

**Паттерн 3: Real-time scoring интеграция**
```sql
-- API для real-time скоринга
CREATE FUNCTION udf_PredictChurnRealTime (
    @customer_data NVARCHAR(MAX)
)
RETURNS TABLE
AS
RETURN (
    SELECT 
        JSON_VALUE(@customer_data, '$.CustomerID') AS CustomerID,
        dbo.PredictModel('ChurnModel', @customer_data) AS ChurnProbability,
        dbo.GetModelExplanation('ChurnModel', @customer_data) AS KeyFactors
);

-- Использование в операционных системах
CREATE TRIGGER trg_CheckChurnOnInteraction
ON CustomerInteractions
AFTER INSERT
AS
BEGIN
    INSERT INTO AlertQueue (CustomerID, AlertType, Priority, Details)
    SELECT 
        i.CustomerID,
        'HighChurnRisk',
        1,
        JSON_OBJECT(
            'probability': p.ChurnProbability,
            'factors': p.KeyFactors
        )
    FROM inserted i
    CROSS APPLY udf_PredictChurnRealTime(
        (SELECT * FROM Customers WHERE CustomerID = i.CustomerID FOR JSON PATH)
    ) p
    WHERE p.ChurnProbability > 0.8;
END;
```

#### **4.3. BI дашборды с интегрированным Data Mining**

```sql
-- Дашборд для управления оттоком клиентов
CREATE VIEW vw_ChurnManagementDashboard
AS
WITH CustomerSegments AS (
    SELECT 
        c.RFM_Cluster,
        c.ChurnScore,
        CASE 
            WHEN c.ChurnScore > 0.7 THEN 'Critical'
            WHEN c.ChurnScore > 0.4 THEN 'At Risk'
            ELSE 'Safe'
        END AS RiskSegment,
        c.NextBestAction,
        s.SalesLastMonth,
        s.SalesLastYear
    FROM Customers c
    LEFT JOIN SalesSummary s ON c.CustomerID = s.CustomerID
)
SELECT 
    RiskSegment,
    RFM_Cluster,
    NextBestAction,
    COUNT(*) AS CustomerCount,
    AVG(ChurnScore) AS AvgChurnScore,
    SUM(SalesLastMonth) AS TotalSalesLastMonth,
    SUM(SalesLastYear) AS TotalSalesLastYear,
    SUM(SalesLastMonth) / COUNT(*) AS AvgSalesPerCustomer
FROM CustomerSegments
GROUP BY 
    RiskSegment,
    RFM_Cluster,
    NextBestAction;
```

---

### **Часть 5. Современные подходы и тренды**

#### **5.1. AutoML (Automated Machine Learning)**

```sql
-- Пример AutoML подхода
EXEC sp_execute_external_script
@language = N'Python',
@script = N'
from azureml.train.automl import AutoMLConfig
from sklearn.model_selection import train_test_split

# Автоматический подбор модели
automl_config = AutoMLConfig(
    task="classification",
    primary_metric="AUC",
    training_data=train_data,
    label_column_name="ChurnLabel",
    n_cross_validations=5,
    max_concurrent_iterations=4,
    experiment_timeout_hours=0.5
)

# Запуск AutoML
automl_run = experiment.submit(automl_config)
best_model = automl_run.get_output()
'
```

#### **5.2. MLOps и управление жизненным циклом моделей**

```yaml
# Конвейер MLOps (пример)
pipeline:
  stages:
    - data_validation
    - feature_engineering
    - model_training
    - model_evaluation
    - model_registry
    - deployment
    - monitoring
  
  triggers:
    - schedule: "0 0 * * *"  # Ежедневно
    - data_drift: >10%
    - performance_drop: >5%
```

#### **5.3. Explainable AI (XAI) в бизнес-контексте**

```sql
-- Интерпретируемость моделей
CREATE PROCEDURE usp_ExplainPrediction
    @customer_id INT
AS
BEGIN
    WITH Explanation AS (
        SELECT 
            FeatureName,
            FeatureValue,
            Contribution,
            ABS(Contribution) AS AbsContribution
        FROM SHAP_Explain(
            @model = 'ChurnModel',
            @input = (SELECT * FROM Customers WHERE CustomerID = @customer_id)
        )
    )
    SELECT TOP 5 *
    FROM Explanation
    ORDER BY AbsContribution DESC;
END;
```

#### **5.4. Real-time streaming analytics**

```sql
-- Обработка потоковых данных
CREATE STREAMING JOB FraudDetectionJob
AS
SELECT 
    t.TransactionID,
    t.Amount,
    t.Location,
    t.Timestamp,
    -- Real-time scoring
    PREDICT(
        USING MODEL FraudModel,
        t.Amount,
        t.Location,
        TIME_SINCE_LAST(t.CustomerID, t.Timestamp)
    ) AS FraudScore
FROM TransactionStream t
WHERE FraudScore > 0.9
INTO AlertStream;
```

#### **5.5. Современные архитектуры**

**Data Mesh:**
```
┌─────────┐   ┌─────────┐   ┌─────────┐
│Product  │   │Marketing│   │Sales    │
│Data     │   │Data     │   │Data     │
│Product  │   │Product  │   │Product  │
└─────────┘   └─────────┘   └─────────┘
       │            │            │
       └────────────┴────────────┘
                │
          ┌─────────────┐
          │Data Mesh    │
          │Platform     │
          └─────────────┘
```

---

### **3. Заключение**

**Ключевые выводы:**

1.  **Data Mining** — это мост между данными и решениями в BI/СППР.
2.  **CRISP-DM** — стандартная методология для управляемого процесса извлечения знаний.
3.  **Интеграция DM с OLAP** создает синергетический эффект для аналитики.
4.  **Современные подходы** (AutoML, MLOps, XAI) делают Data Mining более доступным и надежным.

**Рекомендации по внедрению:**

1.  **Начинайте с бизнес-проблем,** а не с данных или алгоритмов.
2.  **Инвестируйте в подготовку данных** — 80% успеха зависит от качества данных.
3.  **Используйте итеративный подход** — быстрое прототипирование, валидация, улучшение.
4.  **Интегрируйте результаты** в операционные процессы и BI-системы.
5.  **Мониторьте и поддерживайте** модели — дрифт данных неизбежен.

**Тренды будущего:**
- **Автоматизация** всего pipeline (AutoML, AutoFE)
- **Real-time интеллектуальные системы**
- **Глубокая интеграция** с бизнес-процессами
- **Ответственный AI** (этика, объяснимость, безопасность)
- **Демократизация** аналитики (citizen data scientists)

**Итог:** Data Mining превратилась из эзотерической дисциплины в **ключевой компонент современной бизнес-аналитики**. Умение извлекать знания из данных и превращать их в действия — это **критическая компетенция** для организаций в эпоху data-driven принятия решений. Успешные компании используют Data Mining не как отдельный проект, а как **непрерывный процесс создания конкурентных преимуществ**.