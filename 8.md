### Оптимизация запросов в современных СУБД: от планировщика до исполнения

Обработка запроса в современной СУБД — это многоэтапный процесс трансляции декларативного SQL-запроса в эффективный исполняемый код. Этот процесс можно разделить на два макроэтапа: **компиляция (оптимизация)** и **исполнение**.

```
SQL-запрос → Парсинг и валидация → Логическая оптимизация → Физическая оптимизация (Планировщик) → Генерация плана → Исполнение плана → Результат
```

---

### **Часть 1. Фазы компиляции и роль планировщика (Query Optimizer)**

**Оптимизатор запросов** — это самый сложный и интеллектуальный компонент СУБД. Его задача: **найти не любой, а самый эффективный план выполнения** за разумное время.

#### **Фаза 1: Парсинг и валидация (Parsing & Binding)**
*   **Лексический и синтаксический анализ:** Разбор текста SQL, проверка грамматики, построение **синтаксического дерева (Parse Tree)**.
*   **Семантический анализ (Binding):** Проверка существования объектов (таблиц, столбцов), соответствия типов данных, прав доступа. Результат — **дерево операторов (Query Tree/Algebraic Tree)**, где узлы — логические операции (`SELECT`, `JOIN`, `FILTER`).

#### **Фаза 2: Логическая оптимизация (Logical Optimization / Rewriting)**
*   **Цель:** Преобразовать исходное дерево запроса в **логически эквивалентное, но более эффективное для дальнейшей обработки**.
*   **Применяются правила на основе реляционной алгебры:**
    *   **Предикатный pushdown:** Перемещение условий фильтрации (`WHERE`) как можно ближе к сканированию таблицы, чтобы уменьшить размер промежуточных результатов.
    *   **Удаление избыточных операций:** Устранение дублирующих `JOIN`, исключение неиспользуемых столбцов.
    *   **Перезапись подзапросов:** Преобразование коррелированных подзапросов в `JOIN` (часто более эффективный).
    *   **Вычисление константных выражений:** `WHERE price > 100*0.9` → `WHERE price > 90`.

#### **Фаза 3: Физическая оптимизация (Physical Optimization / Cost-Based Optimization)**
Это **сердце планировщика**. Здесь логический план превращается в физический.
*   **Генерация альтернативных планов:** Для каждой логической операции существует множество физических реализаций (алгоритмов). Например, `JOIN` можно выполнить через Nested Loops, Hash Join или Merge Join. Оптимизатор генерирует пространство возможных планов.
*   **Оценка стоимости (Cost Estimation):** Для каждого кандидата-плана вычисляется **предполагаемая стоимость**.
    *   **Модель стоимости:** Включает CPU-cost (обработка строк), I/O-cost (чтение страниц), memory-cost (использование оперативной памяти).
    *   **Ключевые входные данные для оценки:**
        1.  **Статистика по таблицам и индексам:** Распределение данных (гистограммы), количество уникальных значений (cardinality), количество строк, глубина индекса.
        2.  **Статистика по системным ресурсам:** Стоимость последовательного/случайного I/O, стоимость обработки строки CPU.
*   **Выбор плана с минимальной стоимостью:** План с наименьшей совокупной оценочной стоимостью выбирается для исполнения.

**Парадокс оптимизатора:** Сам процесс поиска оптимального плана требует ресурсов. Поэтому СУБД использует эвристики и ограничивает пространство поиска (например, не рассматривает все возможные перестановки `JOIN` для большого числа таблиц).

---

### **Часть 2. Ключевые структуры данных и статистика**

Качество оценки стоимости **полностью зависит от точности статистики**.

1.  **Базовая статистика таблицы:**
    *   `num_rows` — общее число строк.
    *   `num_blocks` — число занятых страниц/блоков.

2.  **Статистика по столбцам (Column Statistics):**
    *   **Количество уникальных значений (NDV — Number of Distinct Values).**
    *   **Гистограмма (Histogram):** Показывает распределение данных в столбце. Не просто `MIN/MAX`, а разбиение на "корзины" (buckets) с примерным количеством строк в каждом диапазоне значений. Критична для оценки селективности предикатов типа `WHERE col > 100`.
    *   **Количество `NULL`-значений.**

3.  **Статистика по индексам:**
    *   Количество уровней в B-дереве (`BLEVEL`).
    *   Количество листовых блоков (`LEAF_BLOCKS`).
    *   **Плотность кластеризации (Clustering Factor — Oracle) / Фрагментация (SQL Server):** Показывает, насколько порядок строк в таблице соответствует порядку в индексе. Низкий фактор кластеризации делает индексный доступ более эффективным.

**Сбор статистики** обычно выполняется автоматически, но может требовать ручного управления для очень больших или быстро меняющихся таблиц.

---

### **Часть 3. Основные классы алгоритмов выполнения (Physical Operators)**

Оптимизатор выбирает физические операторы для каждой логической операции.

#### **3.1. Методы доступа к данным (Access Methods)**
*   **Последовательное сканирование (Sequential/Table Scan):** Чтение всех страниц таблицы. Эффективно для выборки >15-20% данных или при отсутствии подходящего индекса.
*   **Сканирование индекса (Index Scan):**
    *   **Index Range Scan:** Поиск по диапазону в B-дереве. Эффективен для высокоселективных предикатов.
    *   **Index Full Scan:** Чтение всего индекса (когда индекс покрывает все нужные столбцы).
    *   **Index Unique Scan:** Точечный доступ по уникальному ключу.
*   **Сканирование по идентификатору строки (Row ID Lookup / Bookmark Lookup):** Дополнительный шаг после некластеризованного индекса для получения остальных столбцов строки. Может быть дорогим при массовом доступе.

#### **3.2. Алгоритмы соединения (Join Algorithms)**
*   **Nested Loops Join:**
    *   **Принцип:** Для каждой строки внешней (outer) таблицы ищется соответствие во внутренней (inner) таблице (часто по индексу).
    *   **Плюсы:** Эффективен, когда одна таблица мала или есть эффективный индекс для поиска во второй.
    *   **Минусы:** Катастрофически медлен при больших наборах без индекса (`O(n*m)`).

*   **Hash Join:**
    *   **Принцип:** 1) Построение хэш-таблицы по ключу соединения из меньшей (build) таблицы. 2) Проба (probe) для каждой строки большей таблицы.
    *   **Плюсы:** Очень эффективен для соединения больших нефрагментированных наборов, особенно при отсутствии индексов. Линейная сложность `O(n+m)` после построения хэш-таблицы.
    *   **Минусы:** Требует много памяти. Неэффективен для неравенств (`>`, `<`) и если хэш-таблица не помещается в память (происходит сброс на диск).

*   **Merge (Sort-Merge) Join:**
    *   **Принцип:** 1) Сортировка обоих входных наборов по ключу соединения. 2) Слияние двух отсортированных потоков.
    *   **Плюсы:** Эффективен, если данные уже отсортированы (например, по индексу) или для соединения по неравенствам.
    *   **Минусы:** Требует сортировки, которая ресурсоемка при больших объемах.

**Выбор алгоритма** зависит от оцененных размеров данных, наличия индексов, доступной памяти и требуемого порядка результата.

---

### **Часть 4. Современные методы оптимизации**

#### **4.1. Адаптивное выполнение запросов (Adaptive Query Execution)**
Проблема классического подхода: план фиксируется на этапе компиляции на основе *предположений*. Если оценки неверны, плохой план исполняется до конца.
*   **Решение:** Система **мониторит выполнение в реальном времени** и может адаптировать план "на лету".
    *   **Пример 1 (Spark, DuckDB):** Если в `Hash Join` выясняется, что размер одной таблицы сильно превысил оценку, система может динамически переключиться на `Broadcast Hash Join` или даже сменить сторону построения хэш-таблицы.
    *   **Пример 2 (SQL Server Adaptive Joins):** Планировщик создает "гибридный" план, который откладывает выбор между `Nested Loops` и `Hash Join` до момента выполнения, после анализа реального размера промежуточного результата.

#### **4.2. Интеллектуальные возможности (AI/ML) и advanced оптимизации**
*   **Модели, обучающиеся на истории выполнения (Learned Components):**
    *   **Улучшенная оценка кардинальности:** ML-модели, обученные на реальных данных выполнения, предсказывают размеры результатов точнее, чем традиционные гистограммы.
    *   **Рекомендации по индексам и материализованным представлениям:** Анализ рабочей нагрузки для предложения оптимальных индексов (например, `CREATE INDEX` или `DROP INDEX`).
*   **JIT-компиляция запросов (Just-In-Time Compilation):** Преобразование критических частей плана запроса (например, циклов вычислений в агрегациях) в машинный код для выполнения на CPU, минуя интерпретатор. Используется в **HyPer**, **MemSQL**, **SQL Server Hekaton**.
*   **Векторизованное исполнение (Vectorized Execution):** Обработка не одной строки за раз (row-at-a-time), а **пакета строк (batch)**, обычно от 100 до 1000. Это позволяет эффективно использовать инструкции SIMD (Single Instruction Multiple Data) процессора и уменьшить накладные расходы на управление. Ключевая технология в **ClickHouse**, **Snowflake**, **Amazon Redshift**.

---

### **3. Заключение: Иерархия оптимизаций**

Оптимизация запросов — многоуровневая дисциплина:
1.  **На уровне запроса (Самый высокий ROI):** Правильная структура запроса, избегание N+1 проблем, корректное использование `JOIN`.
2.  **На уровне схемы и индексов:** Создание корректных индексов, партиционирование, выбор типов данных.
3.  **На уровне планировщика:** Предоставление ему точной статистики, понимание выбранных алгоритмов.
4.  **На уровне выполнения (Современный тренд):** Использование адаптивных и векторизованных методов для компенсации неточностей планирования и максимального использования аппаратуры.

**Ключевой вывод для разработчика:** Нельзя "обмануть" оптимизатор плохим запросом и надеяться, что он это исправит. Понимание его работы позволяет писать запросы, которые **дают оптимизатору возможность найти эффективный план**, и создавать схемы данных, которые **предоставляют ему для этого необходимые инструменты (индексы и статистику)**.